
# Why is deep-learning so rich of Expressivty?

## On Representational Power of Neural Network
> Borrowing a researcher's comment: "How deep-learning work so well still in its infancy." | This project reveals any relevant issues on Expressivity of Deep-Learning with reproducible codes and its visualization


## What is this repository for?
> This repo intends to contrive an **efficient and convenient answer** to the question: "How complex or Which neural architecture is required to solve the given task/problem?" Â 

## Relevant Prior Literatures

> 1. (M.Telgarsky) Neural networks and rational functions 
https://arxiv.org/pdf/1706.03301.pdf
Main Thesis : "As a final piece of the story, note that the conversion between rational functions and ReLU networks is more seamless if instead one converts to rational networks, meaning neural networks where each activation function is a rational
function."

### Refer to
1. https://arxiv.org/pdf/1708.02691.pdf

